{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "b3d44d1a-98cb-4cee-85ea-539e939a73cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "2d9c1c7e-68c6-4572-9464-c7ad6bf568c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumleler=pd.read_excel(\"stopwords.xlsx\")\n",
    "corpus=[]\n",
    "secilim_cumleler = cumleler[\"Lyric\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "f2740868-d96f-4ed8-9500-7dd2be708aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,cumle in cumleler.iterrows():\n",
    "    corpus.append(cumle[\"Cleaned_Lyric\"].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "8946c65e-56d5-473c-a874-75a7378e0161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['derdim', 'var', 'tutamam', 'içimde'], ['gitsem'], ['kalsam', 'neye', 'yarar'], ['anlatamadım'], ['anlamadılar']]\n"
     ]
    }
   ],
   "source": [
    "print(corpus[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "754276a6-aeb6-4d10-8a3e-a4dd6fd33c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Word2Vec(corpus, vector_size=100, window=5, min_count=5, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "d41068b3-ca11-464d-b315-14f966bf6c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.5305093e-03,  1.5184110e-03,  3.2156596e-03,  4.6396223e-03,\n",
       "        8.9695556e-03,  3.0856512e-03,  4.7451542e-03, -8.7480359e-03,\n",
       "        2.6855459e-03, -4.6433855e-04,  8.7211393e-03,  8.8758906e-03,\n",
       "       -8.7424479e-03, -5.8781926e-04, -2.1084597e-04, -4.0384000e-03,\n",
       "        6.6870269e-03,  2.7405622e-03, -5.3028432e-03, -5.1061087e-03,\n",
       "        4.5632650e-03,  4.5080557e-03, -6.8145231e-03, -5.3092581e-03,\n",
       "        4.6808971e-03, -4.0098121e-03, -6.5171602e-03, -1.6464117e-03,\n",
       "       -3.1575796e-03,  8.1641655e-03, -1.9790102e-03, -5.7814354e-03,\n",
       "       -5.0525926e-03,  5.4941103e-03, -9.7299702e-03,  4.9649146e-03,\n",
       "        7.2452133e-03, -1.3081986e-03,  3.9481376e-03,  1.7072195e-03,\n",
       "       -9.2411377e-03, -8.9081004e-03, -4.7135646e-03,  2.7749771e-03,\n",
       "        7.3567024e-03, -9.5890285e-03, -2.1189165e-03, -3.0093689e-03,\n",
       "        7.5103980e-03,  6.1645322e-03, -5.3613627e-04,  5.5571804e-03,\n",
       "        7.7727367e-03,  3.0248661e-03,  8.2111834e-03,  6.8997093e-03,\n",
       "        1.0115513e-02,  2.9182986e-03,  4.1081705e-03,  3.8702623e-03,\n",
       "        1.0126400e-02,  1.5169969e-03,  6.4048325e-03,  3.9692037e-03,\n",
       "       -4.7123926e-03, -6.7644608e-03,  6.6235731e-03,  4.7390996e-03,\n",
       "        7.6290983e-04, -6.3115619e-03,  5.6100790e-03, -4.2388793e-03,\n",
       "        9.5749395e-03, -6.2946733e-03, -6.9921827e-03,  3.3910940e-03,\n",
       "        1.6790864e-06, -6.3462526e-04, -1.0084485e-03, -7.1653747e-03,\n",
       "        9.9531459e-03,  6.8425718e-03, -8.7211626e-03,  2.2492933e-03,\n",
       "        7.3273252e-03, -3.7238366e-04,  3.0899502e-03, -7.0936964e-03,\n",
       "       -1.5102621e-04, -6.1939745e-03,  1.0552197e-03, -6.6496502e-03,\n",
       "       -5.4475395e-03, -6.1620325e-03, -7.9700239e-03,  4.7506420e-03,\n",
       "       -3.5280448e-03, -4.3933187e-03, -1.6901061e-03, -2.9130420e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv[\"sevda\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "8656d516-fe70-4b36-b2a7-db6838086cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('şeyi', 0.32176142930984497), ('gözlerinde', 0.3006485402584076), ('onca', 0.2795473337173462), ('hey', 0.27559611201286316), ('kalbimden', 0.26104462146759033), ('bizim', 0.21584224700927734), ('yaptım', 0.21367724239826202), ('hop', 0.21341481804847717), ('sebebi', 0.21184250712394714), ('allahım', 0.2032465934753418)]\n"
     ]
    }
   ],
   "source": [
    "similar_words = model.wv.most_similar(\"sevda\")\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "d3546c15-42f9-4849-a274-9f6e73e89c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('yağmur', 0.37499961256980896), ('çoktan', 0.29617100954055786), ('gül', 0.29091382026672363), ('acı', 0.28664401173591614), ('bodrum', 0.2750236690044403), ('aynı', 0.27296915650367737), ('kör', 0.2685301899909973), ('yere', 0.2632724344730377), ('erir', 0.260274201631546), ('kalbim', 0.25639471411705017)]\n"
     ]
    }
   ],
   "source": [
    "similar_words = model.wv.most_similar(\"aşk\")\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "1ff98739-7066-43fa-96fb-118c8dfadb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('var', 0.4268745481967926), ('adam', 0.3633093237876892), ('yıllar', 0.3460054099559784), ('gönlüm', 0.34077757596969604), ('gönül', 0.34040969610214233), ('geri', 0.3353092670440674), ('sende', 0.3337835371494293), ('sadece', 0.30759909749031067), ('yoluna', 0.30621445178985596), ('geldim', 0.30201005935668945)]\n"
     ]
    }
   ],
   "source": [
    "similar_words = model.wv.most_similar(\"ayrılık\")\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "706c2a88-af2f-46b5-bbdb-19f858fcc027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('inan', 0.3768545687198639), ('gülen', 0.3561934530735016), ('yere', 0.34783118963241577), ('adam', 0.3010145127773285), ('bodrum', 0.30078527331352234), ('acı', 0.29388898611068726), ('sadece', 0.2811599373817444), ('canım', 0.2770226299762726), ('yolda', 0.27025386691093445), ('mıyım', 0.2634398341178894)]\n"
     ]
    }
   ],
   "source": [
    "similar_words = model.wv.most_similar(\"hüzün\")\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "4a9c84e1-d442-432f-90f9-3ac625377aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var: 140 kez geçti.\n",
      "aşk: 124 kez geçti.\n",
      "gel: 120 kez geçti.\n",
      "zaman: 74 kez geçti.\n",
      "gece: 72 kez geçti.\n",
      "oldu: 67 kez geçti.\n",
      "yalan: 64 kez geçti.\n",
      "deli: 59 kez geçti.\n",
      "zor: 54 kez geçti.\n",
      "söyle: 51 kez geçti.\n",
      "olur: 49 kez geçti.\n",
      "geri: 46 kez geçti.\n",
      "son: 45 kez geçti.\n",
      "tek: 45 kez geçti.\n",
      "güzel: 45 kez geçti.\n",
      "olsun: 44 kez geçti.\n",
      "boş: 38 kez geçti.\n",
      "dön: 38 kez geçti.\n",
      "aynı: 36 kez geçti.\n",
      "yeter: 35 kez geçti.\n"
     ]
    }
   ],
   "source": [
    "word_counts = {word: model.wv.get_vecattr(word, \"count\") for word in model.wv.index_to_key}\n",
    "\n",
    "# En fazla geçen 20 kelimeyi bulun\n",
    "top_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "\n",
    "# Sonuçları yazdır\n",
    "for word, count in top_words:\n",
    "    print(f\"{word}: {count} kez geçti.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "79def542-57d1-4d16-8ed7-cfe9a7b9bb44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var: 140 kez geçti.\n",
      "Benzer kelimeler: ayrılık, boş, i̇nsan, söyle, acı\n",
      "\n",
      "aşk: 124 kez geçti.\n",
      "Benzer kelimeler: yağmur, çoktan, gül, acı, bodrum\n",
      "\n",
      "gel: 120 kez geçti.\n",
      "Benzer kelimeler: geri, gönül, erir, zor, yalan\n",
      "\n",
      "zaman: 74 kez geçti.\n",
      "Benzer kelimeler: yaşamak, yarim, yanına, oldu, ölürüm\n",
      "\n",
      "gece: 72 kez geçti.\n",
      "Benzer kelimeler: canım, tek, anda, yâr, gel\n",
      "\n",
      "oldu: 67 kez geçti.\n",
      "Benzer kelimeler: dedi, ömür, git, olmuş, geri\n",
      "\n",
      "yalan: 64 kez geçti.\n",
      "Benzer kelimeler: yeni, dert, dolu, giden, inan\n",
      "\n",
      "deli: 59 kez geçti.\n",
      "Benzer kelimeler: yeter, koş, dedi, yarim, yar\n",
      "\n",
      "zor: 54 kez geçti.\n",
      "Benzer kelimeler: ederim, gel, olsa, sandım, sanma\n",
      "\n",
      "söyle: 51 kez geçti.\n",
      "Benzer kelimeler: günlere, var, birer, acı, bırakıp\n",
      "\n",
      "olur: 49 kez geçti.\n",
      "Benzer kelimeler: i̇nsan, i̇şte, geri, gözü, gönlüm\n",
      "\n",
      "geri: 46 kez geçti.\n",
      "Benzer kelimeler: gül, gel, dedi, oldu, git\n",
      "\n",
      "son: 45 kez geçti.\n",
      "Benzer kelimeler: yeni, sonra, sıkı, kalk, koşup\n",
      "\n",
      "tek: 45 kez geçti.\n",
      "Benzer kelimeler: kalbin, yalancı, gece, ömür, verilir\n",
      "\n",
      "güzel: 45 kez geçti.\n",
      "Benzer kelimeler: geçer, dön, oğlum, aldın, bunlar\n",
      "\n",
      "olsun: 44 kez geçti.\n",
      "Benzer kelimeler: bırakıp, gidersen, döneceksin, yar, yavrum\n",
      "\n",
      "boş: 38 kez geçti.\n",
      "Benzer kelimeler: var, git, yar, yalan, senle\n",
      "\n",
      "dön: 38 kez geçti.\n",
      "Benzer kelimeler: bunu, aşkı, geri, olur, i̇şte\n",
      "\n",
      "aynı: 36 kez geçti.\n",
      "Benzer kelimeler: tatlı, anlar, aklıma, sadece, seven\n",
      "\n",
      "yeter: 35 kez geçti.\n",
      "Benzer kelimeler: deli, doya, olsam, kalbimi, sabret\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Her bir kelimenin en benzer 5 kelimesini bulun\n",
    "similar_words_dict = {}\n",
    "\n",
    "for word, count in top_words:\n",
    "    similar_words = model.wv.most_similar(word, topn=6)\n",
    "    # ’, değerini çıkar\n",
    "    similar_words = [similar_word for similar_word in similar_words if similar_word[0] != '’']\n",
    "    # En fazla 5 kelime kullan\n",
    "    similar_words_dict[word] = [similar_word[0] for similar_word in similar_words[:5]]\n",
    "\n",
    "# Sonuçları yazdırın\n",
    "for word, count in top_words:\n",
    "    print(f\"{word}: {count} kez geçti.\")\n",
    "    print(f\"Benzer kelimeler: {', '.join(similar_words_dict[word])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "26ee0d5f-0540-46a2-813e-faa8d034ed59",
   "metadata": {},
   "outputs": [],
   "source": [
    "secilen_cumleler_indexleri = random.sample(list(enumerate(secilim_cumleler)), 5)\n",
    "\n",
    "# Cümleleri etiketleme (TaggedDocument kullanarak)\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(sentence.lower()), tags=[str(index)]) for index, sentence in secilen_cumleler_indexleri]\n",
    "\n",
    "# Doc2Vec modelini eğitme\n",
    "model = Doc2Vec(vector_size=100, window=5, min_count=1, workers=4, epochs=100)\n",
    "model.build_vocab(tagged_data)\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "19dcc0eb-244e-4a04-a6f6-dbe88592d715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Seçili Cümle (Index 6176): yalnızlığımı alamaz\n",
      "En Benzer (0.19) - Index 3216: dudaklarında mühür olmak\n",
      "En Benzer (0.04) - Index 4175: bütün güllerden derin\n",
      "En Benzer (0.04) - Index 91: bir kar tanesi ol erir ağzımda\n",
      "\n",
      "2. Seçili Cümle (Index 3216): dudaklarında mühür olmak\n",
      "En Benzer (0.23) - Index 91: bir kar tanesi ol erir ağzımda\n",
      "En Benzer (0.19) - Index 6176: yalnızlığımı alamaz\n",
      "En Benzer (-0.02) - Index 4175: bütün güllerden derin\n",
      "\n",
      "3. Seçili Cümle (Index 4175): bütün güllerden derin\n",
      "En Benzer (0.08) - Index 91: bir kar tanesi ol erir ağzımda\n",
      "En Benzer (0.04) - Index 6176: yalnızlığımı alamaz\n",
      "En Benzer (-0.02) - Index 3216: dudaklarında mühür olmak\n",
      "\n",
      "4. Seçili Cümle (Index 91): bir kar tanesi ol erir ağzımda\n",
      "En Benzer (0.23) - Index 3216: dudaklarında mühür olmak\n",
      "En Benzer (0.08) - Index 4175: bütün güllerden derin\n",
      "En Benzer (0.04) - Index 6176: yalnızlığımı alamaz\n",
      "\n",
      "5. Seçili Cümle (Index 2755): hayatın akışına uyamıyorum\n",
      "En Benzer (-0.02) - Index 91: bir kar tanesi ol erir ağzımda\n",
      "En Benzer (-0.03) - Index 4175: bütün güllerden derin\n",
      "En Benzer (-0.04) - Index 6176: yalnızlığımı alamaz\n"
     ]
    }
   ],
   "source": [
    "# Seçili cümlelerin vektörlerini oluştur\n",
    "selected_sentences_vectors = [model.dv[str(index)] for index, _ in secilen_cumleler_indexleri]\n",
    "\n",
    "# Benzer cümleleri bul\n",
    "similar_sentences = []\n",
    "\n",
    "# Her bir seçilen cümle için en benzer 3 cümleyi bulma\n",
    "for selected_index, (index, sentence) in enumerate(secilen_cumleler_indexleri):\n",
    "    selected_vector = model.dv[str(index)]  # Seçilen cümle vektörü\n",
    "    similarities = model.dv.most_similar([selected_vector], topn=4)  # En benzer cümleleri bulma\n",
    "    \n",
    "    # Benzerlik derecesine göre sırala ve en benzer 3 cümleyi al\n",
    "    top_similarities = sorted(similarities, key=lambda x: x[1], reverse=True)[1:4]\n",
    "\n",
    "    # Sonuçları ekrana yazdır\n",
    "    print(f\"\\n{selected_index + 1}. Seçili Cümle (Index {index}): {sentence}\")\n",
    "    for idx, sim in top_similarities:\n",
    "        similar_sentence = secilim_cumleler[int(idx)]\n",
    "        print(f\"En Benzer ({sim:.2f}) - Index {idx}: {similar_sentence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce1ab22-097c-473f-8e2c-8a66ce1122fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
